# Data Engineer Assistant Configuration - Following Snowflake Guide
# Performance optimization agent using comprehensive SNOWFLAKE.ACCOUNT_USAGE data

agent:
  name: "DATA_ENGINEER_ASSISTANT"
  display_name: "Data Engineer Assistant"
  comment: "AI-powered assistant analyzing query history and usage patterns to deliver personalized, actionable recommendations to lower costs and improve performance - integrated with existing ACME Intelligence platform"
  database: "SNOWFLAKE_INTELLIGENCE"
  schema: "AGENTS"
  models:
    orchestration: "auto"

instructions:
  response: >
    Transform Snowflake performance analysis into actionable, data-driven recommendations:
    1. IMMEDIATE ROI OPPORTUNITIES - Highlight cost optimization and performance gains with projected savings
    2. QUERY PERFORMANCE ANALYSIS - Identify slowest queries with specific optimization recommendations
    3. WAREHOUSE EFFICIENCY - Analyze utilization patterns and recommend Gen 2 upgrades where beneficial
    4. COMPILATION ERROR RESOLUTION - Provide step-by-step guidance for fixing compilation issues
    5. FEATURE DISCOVERY - Identify unused Snowflake features that could improve performance (Dynamic Tables, etc.)
    6. CREATE VISUALIZATIONS for performance analysis:
       - Query performance trends (execution time over time)
       - Warehouse utilization patterns (credit consumption, queue times)
       - Cost analysis charts (spend by warehouse, user, query type)
       - Performance bottleneck identification (slowest queries, resource consumption)
    7. Use data engineer language with specific SQL improvements and warehouse optimizations
    8. Focus on proactive optimization rather than reactive troubleshooting
    9. Provide concrete next steps with expected business impact and ROI projections
    10. Base all recommendations on actual usage patterns rather than generic best practices
  
  orchestration: >
    OVERALL: Analyze actual usage patterns in parallel for comprehensive performance optimization recommendations.
    Use 'Query Usage Analytics' for detailed query history analysis, bottleneck identification, and cost optimization opportunities.
    Simultaneously leverage 'Search Performance Documentation' for best practice context when available.
    Concurrently use 'Send Performance Report' for actionable communication of findings with technical stakeholders.
    Always provide data-driven recommendations based on real usage data rather than generic advice.
  
  sample_questions:
    - "What are my slowest queries and how can I optimize them?"
    - "Which warehouses are inefficient and should I upgrade to Gen 2?"
    - "Show me cost optimization opportunities with projected savings"
    - "What compilation errors am I seeing and how do I fix them?"
    - "Which unused Snowflake features could improve my performance?"
    - "Analyze my warehouse utilization and recommend optimizations"
    - "What are my biggest cost drivers and how can I reduce them?"
    - "Show me query performance trends over the last month"
    - "Which users or workloads are consuming the most credits?"
    - "Recommend Dynamic Tables or other features for my workload patterns"
    - "What's my query queue time and how can I improve it?"
    - "Show me opportunities to consolidate or right-size warehouses"
    - "Analyze credit consumption patterns and identify waste"
    - "Which queries are spilling to disk and how can I fix them?"

# Use existing COMPUTE_WH warehouse to integrate with current setup
default_execution_environment: &default_execution_environment
  type: "warehouse"
  warehouse: "COMPUTE_WH"

tools:
  # Main usage analytics tool using comprehensive semantic view with 85+ columns
  - name: "Query Usage Analytics"
    type: "cortex_analyst_text_to_sql"
    description: >
      SEMANTIC VIEW: ACME_INTELLIGENCE.SEMANTIC_MODELS.snowflake_usage_semantic_view
      - Database: ACME_INTELLIGENCE, Schema: SEMANTIC_MODELS
      - Comprehensive query performance analysis using QUERY_ATTRIBUTION_HISTORY and QUERY_HISTORY
      - Contains all 85+ columns for complete performance, cost, and usage analysis
      - Provides personalized optimization recommendations based on actual usage patterns
      
      KEY USAGE ANALYTICS CAPABILITIES:
      - Query execution times, compilation times, and performance bottlenecks identification
      - Warehouse utilization patterns and credit consumption analysis
      - User and workload analysis for capacity planning and optimization
      - Error analysis and compilation issue identification with resolution guidance
      - Cost analysis by warehouse, user, query type, and time period
      - Queue time analysis and concurrency optimization opportunities
      - Resource consumption patterns and right-sizing recommendations
      - Performance trends analysis and predictive optimization insights
      - Credit attribution analysis and cost optimization opportunities
      - Query acceleration and cache optimization recommendations
      
      OPTIMIZATION PURPOSE: Transform raw usage data into immediate ROI opportunities,
      specific performance improvements, cost reduction strategies, and proactive optimization
      recommendations tailored to your actual Snowflake environment and usage patterns.
    resources:
      semantic_view: "ACME_INTELLIGENCE.SEMANTIC_MODELS.snowflake_usage_semantic_view"
      execution_environment: 
        <<: *default_execution_environment

  # Leverage existing document search for best practices
  - name: "Search Performance Documentation"
    type: "cortex_search"
    description: "Search existing ACME documents for performance optimization context, best practices, and strategic guidance using existing document intelligence infrastructure"
    resources:
      name: "ACME_INTELLIGENCE.SEARCH.acme_document_search"
      max_results: 8
      title_column: "TITLE"
      id_column: "RELATIVE_PATH"
      experimental:
        Diversity:
          GroupBy: ["DOCUMENT_TYPE"]
          MaxResults: 2
        RerankWeights:
          TopicalityMultiplier: 4
          EmbeddingMultiplier: 1.3
          RerankingMultiplier: 1.5

  # Use existing email infrastructure for performance reporting
  - name: "Send Performance Report"
    type: "generic"
    description: "Send performance optimization reports with specific recommendations, projected ROI, and step-by-step implementation guidance using existing email infrastructure"
    input_schema:
      type: "object"
      properties:
        recipient:
          description: "Email address for performance optimization report (data engineers, DBAs, technical stakeholders)"
          type: "string"
        subject:
          description: "Technical subject line highlighting specific performance improvements and cost optimization opportunities"
          type: "string"
        text:
          description: "Comprehensive HTML performance report with specific query optimizations, warehouse recommendations, cost analysis, implementation steps, and projected ROI with technical details"
          type: "string"
      required: ["recipient", "subject", "text"]
    resources:
      type: "procedure"
      identifier: "AGENT_TOOLS_CENTRAL.AGENT_TOOLS.SEND_MAIL"
      name: "SEND_MAIL(VARCHAR, VARCHAR, VARCHAR)"
      execution_environment:
        <<: *default_execution_environment
        query_timeout: 0

  # Custom deep query analysis tool using GET_QUERY_OPERATOR_STATS
  - name: "Deep Query Analysis"
    type: "cortex_analyst_text_to_sql"
    description: >
      Advanced query-specific performance analysis using GET_QUERY_OPERATOR_STATS and system functions.
      Provides detailed execution plan analysis, spilling detection, join optimization, and bottleneck identification.
      
      DEEP ANALYSIS CAPABILITIES:
      - GET_QUERY_OPERATOR_STATS() for execution plan breakdown
      - Operator-level performance bottleneck identification  
      - Spilling severity analysis (local vs remote with GB calculations)
      - Join explosion detection (output_rows / input_rows ratios)  
      - Memory pressure analysis and warehouse sizing recommendations
      - I/O pattern analysis (local_disk_io, remote_disk_io, processing percentages)
      - Execution time breakdown by operator type
      - Specific optimization recommendations based on execution plan
      
      USAGE EXAMPLES:
      - "Analyze query ID 01abc123-def4-5678-9012-345678901234 for performance bottlenecks"
      - "What's causing spilling in my recent slow queries?"
      - "Show me execution plan analysis for queries with remote spilling"
      - "Identify join explosions and memory issues in query XYZ"
      
      Use this for QUERY-SPECIFIC analysis while using the semantic view for WAREHOUSE-LEVEL trends.
    resources:
      semantic_view: "ACME_INTELLIGENCE.SEMANTIC_MODELS.snowflake_usage_semantic_view"
      execution_environment:
        <<: *default_execution_environment

